```{r}

# Charger les bibliothèques nécessaires
library(R6)
# install.packages("nnet")
library(nnet)

# Charger les données Iris
data(iris)
iris$Species <- as.factor(iris$Species)

```


```{r}

# Diviser les données en ensembles d'entraînement et de test
set.seed(42)  # Pour la reproductibilité

data_prep <- DataPreparer$new(use_factor_analysis = FALSE)
prepared_data <- data_prep$prepare_data(iris,"Species", 0.7, stratify = TRUE)


# Accéder aux données préparées
X_train <- prepared_data$X_train
X_test <- prepared_data$X_test
y_train <- prepared_data$y_train
y_test <- prepared_data$y_test

# Check AFDM (avec one hot encoder 32 dimensions) # 27 dimensions sans one hot encoder, encore réduire ?
# print(ncol(X_train))

# Afficher les proportions des classes dans les ensembles d'entraînement et de test
cat("Proportions des classes dans l'ensemble d'entraînement :\n")
print(table(y_train) / length(y_train))
cat("Proportions des classes dans l'ensemble de test :\n")
print(table(y_test) / length(y_test))

# Convertir les données préparées en matrices
X_train_matrix <- as.matrix(X_train)
X_test_matrix <- as.matrix(X_test)

# Convertir la variable cible en valeurs numériques
y_train_numeric <- as.numeric(y_train)
y_test_numeric <- as.numeric(y_test)
```


```{r}
# Initialiser et ajuster le modèle sur l'ensemble d'entraînement
model <- LogisticRegressionMultinomial$new(learning_rate = 0.1, num_iterations = 300, loss="logistique", optimizer="adam", use_early_stopping=TRUE, regularization = "L1")
# lasso F1 = 0.99
# ridge F1 = 0.99
# elasticnet F1 = 0.99
# FALSE = 0.99

model$fit(X_train_matrix, y_train_numeric)
```


```{r}
# Prédire sur l'ensemble de test
predictions <- model$predict(X_test_matrix)
# Afficher les prédictions
print(predictions)
```


```{r}
# Vérifier si des prédictions ont été faites
# Calculer et afficher l'accuracy
accuracy <- sum(predictions == y_test_numeric) / length(y_test_numeric)
cat("Accuracy:", accuracy, "\n")

# Matrice de confusion pour évaluer les performances
confusion_matrix <- table(Predicted = predictions, Actual = y_test_numeric)
print(confusion_matrix)
```


```{r}
#tester la fonction var_select()
model$var_importance()
```

```{r}
#teste de la fonction summary()
model$summary()
```


```{r}
#tester la fonction plot()
model$plot_loss()
```


```{r}
#tester la fonction select_variables()
model$select_variables(4)
```




## nnet model

```{r}
# 
# Initialiser le modèle de régression logistique multinomial
multinom_model <- nnet::multinom(y_train_numeric ~ ., data = as.data.frame(X_train_matrix))

# Faire des prédictions sur l'ensemble de test
multinom_predictions <- predict(multinom_model, newdata = as.data.frame(X_test_matrix))

# Vérifier les prédictions
print("Multinomial Model Predictions:")
print(multinom_predictions)

# Calculer et afficher l'accuracy
multinom_accuracy <- sum(multinom_predictions == y_test_numeric) / length(y_test_numeric)
cat("Multinomial Model Accuracy:", multinom_accuracy, "\n")

# Calculer et afficher la matrice de confusion
multinom_confusion_matrix <- table(Predicted = multinom_predictions, Actual = y_test_numeric)
print("Multinomial Model Confusion Matrix:")
print(multinom_confusion_matrix)
```
