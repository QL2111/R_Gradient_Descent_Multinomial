```{r}

# Charger les bibliothèques nécessaires
library(R6)
# install.packages("nnet")
library(nnet)

# Charger le jeu de données depuis un fichier local après téléchargement de Kaggle

setwd("D:/M2 SISE/Programmation R/Projet R/R_Gradient_Descent_Multinomial/data") # Remplacez par le chemin correct
data <- read.csv(file = "user_behavior_dataset.csv")
data
```


```{r}
# S'assurer que la variable cible est un facteur
data$Device.Model <- as.factor(data$User.Behavior.Class)

# Diviser les données en ensembles d'entraînement et de test
set.seed(42)  # Pour la reproductibilité

```


```{r}
data_prep <- DataPreparer$new(use_factor_analysis = FALSE)
prepared_data <- data_prep$prepare_data(data, "User.Behavior.Class", 0.7, stratify = TRUE)


# Accéder aux données préparées
X_train <- prepared_data$X_train
X_test <- prepared_data$X_test
y_train <- prepared_data$y_train
y_test <- prepared_data$y_test

# Check AFDM (avec one hot encoder 32 dimensions) # 27 dimensions sans one hot encoder, encore réduire ?
# print(ncol(X_train))

# Afficher les proportions des classes dans les ensembles d'entraînement et de test
cat("Proportions des classes dans l'ensemble d'entraînement :\n")
print(table(y_train) / length(y_train))
cat("Proportions des classes dans l'ensemble de test :\n")
print(table(y_test) / length(y_test))

# Convertir les données préparées en matrices
X_train_matrix <- as.matrix(X_train)
X_test_matrix <- as.matrix(X_test)

# Convertir la variable cible en valeurs numériques
y_train_numeric <- as.numeric(y_train)
y_test_numeric <- as.numeric(y_test)

```


```{r}
X_train <- as.matrix(prepared_X_train)
X_test <- as.matrix(prepared_X_test)

# Convertir la variable cible en valeurs numériques
y_train <- as.numeric(y_train)
y_test <- as.numeric(y_test)

```



```{r}
# Initialiser et ajuster le modèle sur l'ensemble d'entraînement
model <- LogisticRegressionMultinomial$new(learning_rate = 0.1, num_iterations = 300,loss="logistique", optimizer="sgd", use_early_stopping=TRUE)
model$fit(X_train_matrix, y_train_numeric)
```


```{r}
predictions <- model$predict(X_test_matrix)
print(predictions)
```

```{r}
# Vérifier si des prédictions ont été faites
#print(y_test)
# Calculer et afficher l'accuracy
accuracy <- sum(predictions == y_test_numeric) / length(y_test_numeric)
cat("Accuracy:", accuracy, "\n")
```
```{r}
#tester la fonction var_select()
model$var_importance()
```
```{r}
#teste de la fonction summary()
model$summary()
```


```{r}
#tester la fonction plot()
model$plot_loss()
```


```{r}
#tester la fonction var_select()
model$select_variables(5)
```


```{r}
confusion_matrix <- table(Predicted = predictions, Actual = y_test_numeric)
print(confusion_matrix)
```




nnet model

```{r}
# 
# Initialiser le modèle de régression logistique multinomial
multinom_model <- nnet::multinom(y_train_numeric ~ ., data = as.data.frame(X_train_matrix))

# Faire des prédictions sur l'ensemble de test
multinom_predictions <- predict(multinom_model, newdata = as.data.frame(X_test_matrix))

# Vérifier les prédictions
print("Multinomial Model Predictions:")
print(multinom_predictions)

# Calculer et afficher l'accuracy
multinom_accuracy <- sum(multinom_predictions == y_test_numeric) / length(y_test_numeric)
cat("Multinomial Model Accuracy:", multinom_accuracy, "\n")

# Calculer et afficher la matrice de confusion
multinom_confusion_matrix <- table(Predicted = multinom_predictions, Actual = y_test_numeric)
print("Multinomial Model Confusion Matrix:")
print(multinom_confusion_matrix)
```








