```{r}

# Charger les bibliothèques nécessaires
library(R6)
# install.packages("nnet")
library(nnet)

# Charger le jeu de données depuis un fichier local après téléchargement de Kaggle

setwd("D:/M2 SISE/Programmation R/Projet R/R_Gradient_Descent_Multinomial/R") # Remplacez par le chemin correct
data <- read.csv(file = "user_behavior_dataset.csv")
data
```


```{r}
# S'assurer que la variable cible est un facteur
data$Device.Model <- as.factor(data$Device.Model)

# Diviser les données en ensembles d'entraînement et de test
set.seed(42)  # Pour la reproductibilité

```


```{r}
train_indices <- sample(1:nrow(data), size = 0.7 * nrow(data))  # 70% pour l'entraînement
train_data <- data[train_indices, ]
test_data <- data[-train_indices, ]

# Séparer les caractéristiques et la variable cible
X_train <- train_data[, -which(names(train_data) == "Device.Model")]
y_train <- train_data$Device.Model

X_test <- test_data[, -which(names(test_data) == "Device.Model")]
y_test <- test_data$Device.Model
```


```{r}
# Afficher les dimensions des ensembles d'entraînement et de test avant le traitement
dim(X_train)
dim(X_test)
# Préparer les prédicteurs sans inclure la variable cible
data_prep <- DataPreparer$new(use_factor_analysis = FALSE)  # standardisation + one hot encoding
prepared_X_train <- data_prep$prepare_data(X_train)
# Préparer les mêmes transformation aux données de test
prepared_X_test <- data_prep$prepare_data(X_test)

# Enlever les duplicates
cat("Number of duplicates in prepared training data:", sum(duplicated(prepared_X_train)), "\n")
cat("Number of duplicates in prepared test data:", sum(duplicated(prepared_X_test)), "\n")
prepared_X_train <- prepared_X_train[!duplicated(prepared_X_train), ]
prepared_X_test <- prepared_X_test[!duplicated(prepared_X_test), ]
cat("Number of duplicates in prepared training data after removal:", sum(duplicated(prepared_X_train)), "\n")
cat("Number of duplicates in prepared test data after removal:", sum(duplicated(prepared_X_test)), "\n")

# Afficher les dimensions des données préparées
dim(prepared_X_train)
dim(prepared_X_test)

# Afficher la proportion de valeurs manquantes dans les données préparées
cat("Proportion of missing values in prepared training data:", mean(is.na(prepared_X_train)), "\n")
cat("Proportion of missing values in prepared test data:", mean(is.na(prepared_X_test)), "\n")

```


```{r}
X_train <- as.matrix(prepared_X_train)
X_test <- as.matrix(prepared_X_test)

# Convertir la variable cible en valeurs numériques
y_train <- as.numeric(y_train)
y_test <- as.numeric(y_test)

```



```{r}
# Initialiser et ajuster le modèle sur l'ensemble d'entraînement
model <- LogisticRegressionMultinomial$new()
model$fit(X_train, y_train)
```


```{r}
predictions <- model$predict(X_test)
print(predictions)
```

```{r}
# Vérifier si des prédictions ont été faites
#print(y_test)
# Calculer et afficher l'accuracy
accuracy <- sum(predictions == y_test) / length(y_test)
cat("Accuracy:", accuracy, "\n")
```
```{r}
#tester la fonction var_select()
model$var_importance()
```
```{r}
#teste de la fonction summary()
model$summary(X_test, y_test)
```


```{r}
#tester la fonction plot()
model$plot_loss()
```


```{r}
#tester la fonction var_select()
#model$var_select(X_train, y_train)
```



```{r}
dim(predictions)
dim(y_test)
```


```{r}
confusion_matrix <- table(Predicted = predictions, Actual = y_test)
print(confusion_matrix)

```


nnet model

```{r}
# 
# Initialiser le modèle de régression logistique multinomial
multinom_model <- nnet::multinom(y_train ~ ., data = as.data.frame(X_train))

# Faire des prédictions sur l'ensemble de test
multinom_predictions <- predict(multinom_model, newdata = as.data.frame(X_test))

# Vérifier les prédictions
print("Multinomial Model Predictions:")
print(multinom_predictions)

# Calculer et afficher l'accuracy
multinom_accuracy <- sum(multinom_predictions == y_test) / length(y_test)
cat("Multinomial Model Accuracy:", multinom_accuracy, "\n")

# Calculer et afficher la matrice de confusion
multinom_confusion_matrix <- table(Predicted = multinom_predictions, Actual = y_test)
print("Multinomial Model Confusion Matrix:")
print(multinom_confusion_matrix)
```
